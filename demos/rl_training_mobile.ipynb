{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2cfc7f7",
   "metadata": {},
   "source": [
    "# Import all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b225355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from enum import IntEnum\n",
    "import time\n",
    "import jsonrpclib\n",
    "import subprocess\n",
    "from subprocess import PIPE, Popen\n",
    "from threading  import Thread\n",
    "import sys\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "from gym import Env, error, spaces, utils\n",
    "from stable_baselines3 import DQN, PPO, A2C, TD3, SAC\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import tempfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import gym\n",
    "from cv2 import QRCodeDetector\n",
    "from pyzbar import pyzbar\n",
    "\n",
    "import olympe\n",
    "from olympe.messages.ardrone3.Piloting import TakeOff, Landing, moveBy, PCMD, moveTo\n",
    "from olympe.messages.ardrone3.PilotingState import FlyingStateChanged, PositionChanged, GpsLocationChanged, moveToChanged\n",
    "from olympe.enums.ardrone3.PilotingState import FlyingStateChanged_State as FlyingState\n",
    "from olympe.messages.ardrone3.GPSSettingsState import GPSFixStateChanged, HomeChanged\n",
    "from olympe.messages.gimbal import set_target, attitude\n",
    "from olympe.messages.camera import (\n",
    "    set_camera_mode,\n",
    "    set_photo_mode,\n",
    "    take_photo,\n",
    "    photo_progress,\n",
    ")\n",
    "from olympe.media import (\n",
    "    media_created,\n",
    "    resource_created,\n",
    "    media_removed,\n",
    "    resource_removed,\n",
    "    resource_downloaded,\n",
    "    indexing_state,\n",
    "    delete_media,\n",
    "    download_media,\n",
    "    download_media_thumbnail,\n",
    "    MediaEvent,\n",
    ")\n",
    "\n",
    "from pynput.keyboard import Listener, Key, KeyCode\n",
    "from collections import defaultdict\n",
    "\n",
    "olympe.log.update_config({\n",
    "    \"loggers\": {\n",
    "        \"olympe\": {\n",
    "                \"handlers\": []\n",
    "            }\n",
    "        },\n",
    "        \"ulog\": {\n",
    "            \"level\": \"OFF\",\n",
    "            \"handlers\": [],\n",
    "        }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380e41c",
   "metadata": {},
   "source": [
    "# Define the constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2702da",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRONE_IP = os.environ.get(\"DRONE_IP\", \"10.202.0.1\")\n",
    "DRONE_MEDIA_PORT = os.environ.get(\"DRONE_MEDIA_PORT\", \"80\")\n",
    "\n",
    "ANAFI_URL = \"http://{}/\".format(DRONE_IP)\n",
    "ANAFI_MEDIA_API_URL = ANAFI_URL + \"api/v1/media/medias/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9719c",
   "metadata": {},
   "source": [
    "# Define the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f459a37",
   "metadata": {},
   "source": [
    "## Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ac1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    def __init__(self, drone):\n",
    "        self.drone = drone\n",
    "        self.home = self.drone.get_state(GpsLocationChanged)\n",
    "        \n",
    "        self.current_cell = self._get_cell(13)\n",
    "        self.invalid_left_cells = [1, 6, 11, 16, 21]\n",
    "        self.invalid_forward_cells = [1, 2, 3, 4, 5]\n",
    "        self.invalid_right_cells = [5, 10, 15, 20, 25]\n",
    "        self.invalid_backward_cells = [21, 22, 23, 24, 25]\n",
    "        \n",
    "        self.Move = IntEnum(\n",
    "            'MOVE',\n",
    "            'FORWARD BACKWARD LEFT RIGHT FORWARD_LEFT FORWARD_RIGHT BACKWARD_LEFT BACKWARD_RIGHT HOVER',\n",
    "            start=0\n",
    "        )\n",
    "        \n",
    "    def take_action(self, action):\n",
    "        next_cell_id = self._get_next_cell_id(action)\n",
    "        next_cell = self._get_cell(next_cell_id)\n",
    "        \n",
    "        old_cell_id, new_cell_id = self.current_cell[\"id\"], next_cell[\"id\"]\n",
    "        if old_cell_id == new_cell_id: \n",
    "            return old_cell_id, new_cell_id, self._get_action_name(action)\n",
    "        \n",
    "        self._move_to_cell(next_cell)\n",
    "        \n",
    "        self.current_cell = next_cell\n",
    "        \n",
    "        return old_cell_id, new_cell_id, self._get_action_name(action)\n",
    "        \n",
    "    def reset(self):\n",
    "        next_cell = self._get_cell(13)\n",
    "        self._move_to_cell(next_cell)\n",
    "        \n",
    "        old_cell_id, new_cell_id = self.current_cell[\"id\"], next_cell[\"id\"]\n",
    "        self.current_cell = next_cell\n",
    "        \n",
    "        return old_cell_id, new_cell_id\n",
    "    \n",
    "    def _get_cell(self, cell_id):\n",
    "        return self._cell_coords[cell_id - 1]\n",
    "    \n",
    "    def _get_action_name(self, action):\n",
    "        direction = str(self.Move(action)).split(\".\")[1]\n",
    "        code = \"\"\n",
    "        for i in direction.split(\"_\"):\n",
    "            if i != \"\":\n",
    "                code += i[0].upper()\n",
    "        \n",
    "        return code\n",
    "#         direction = str(self.Move(action)).split(\".\")[1].capitalize()\n",
    "#         return \"Moving \" + direction if \"hover\" not in direction.lower() else \"Hovering\"\n",
    "    \n",
    "    def _move_to_cell(self, next_cell):        \n",
    "        self.drone(\n",
    "            moveTo(next_cell[\"latitude\"],  next_cell[\"longitude\"], next_cell[\"altitude\"], \"HEADING_DURING\", 90.0)\n",
    "            >> moveToChanged(status=\"DONE\", _timeout=15)\n",
    "        ).wait()\n",
    "    \n",
    "    def _get_next_cell_id(self, action):\n",
    "        if action == self.Move.HOVER:\n",
    "            return self.current_cell[\"id\"]\n",
    "        elif action == self.Move.LEFT:\n",
    "            if self.current_cell[\"id\"] in self.invalid_left_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] - 1\n",
    "        elif action == self.Move.RIGHT:\n",
    "            if self.current_cell[\"id\"] in self.invalid_right_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] + 1\n",
    "        elif action == self.Move.FORWARD:\n",
    "            if self.current_cell[\"id\"] in self.invalid_forward_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] - 5\n",
    "        elif action == self.Move.BACKWARD:\n",
    "            if self.current_cell[\"id\"] in self.invalid_backward_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] + 5\n",
    "        elif action == self.Move.FORWARD_RIGHT:\n",
    "            if self.current_cell[\"id\"] in self.invalid_forward_cells + self.invalid_right_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] - 4\n",
    "        elif action == self.Move.FORWARD_LEFT:\n",
    "            if self.current_cell[\"id\"] in self.invalid_forward_cells + self.invalid_left_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] - 6\n",
    "        elif action == self.Move.BACKWARD_RIGHT:\n",
    "            if self.current_cell[\"id\"] in self.invalid_backward_cells + self.invalid_right_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] + 6\n",
    "        elif action == self.Move.BACKWARD_LEFT:\n",
    "            if self.current_cell[\"id\"] in self.invalid_backward_cells + self.invalid_left_cells:\n",
    "                return self.current_cell[\"id\"]\n",
    "            next_cell_id = self.current_cell[\"id\"] + 4\n",
    "            \n",
    "        return next_cell_id\n",
    "    \n",
    "    @property\n",
    "    def _cell_coords(self):\n",
    "        altitude = 6.0\n",
    "        dlong = 6.8e-5 # in degrees == 5 meters along x-axis (forward[+]-backward[-])\n",
    "        dlat = 7.2e-5 # in degrees == 8 meters along y-axis (left[+]-right[-])\n",
    "        \n",
    "        home_lat = self.home[\"latitude\"]\n",
    "        home_long = self.home[\"longitude\"]\n",
    "        \n",
    "        return [\n",
    "            # cell no. 1\n",
    "            OrderedDict([('id', 1),\n",
    "                         ('latitude', home_lat + 2 * dlat),\n",
    "                         ('longitude', home_long + 2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 2\n",
    "            OrderedDict([('id', 2),\n",
    "                         ('latitude', home_lat + 1 * dlat),\n",
    "                         ('longitude', home_long + 2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 3\n",
    "            OrderedDict([('id', 3),\n",
    "                         ('latitude', home_lat + 0 * dlat),\n",
    "                         ('longitude', home_long + 2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 4\n",
    "            OrderedDict([('id', 4),\n",
    "                         ('latitude', home_lat + -1 * dlat),\n",
    "                         ('longitude', home_long + 2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 5\n",
    "            OrderedDict([('id', 5),\n",
    "                         ('latitude', home_lat + -2 * dlat),\n",
    "                         ('longitude', home_long + 2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 6\n",
    "            OrderedDict([('id', 6),\n",
    "                         ('latitude', home_lat + 2 * dlat),\n",
    "                         ('longitude', home_long + 1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 7\n",
    "            OrderedDict([('id', 7),\n",
    "                         ('latitude', home_lat + 1 * dlat),\n",
    "                         ('longitude', home_long + 1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 8\n",
    "            OrderedDict([('id', 8),\n",
    "                         ('latitude', home_lat + 0 * dlat),\n",
    "                         ('longitude', home_long + 1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 9\n",
    "            OrderedDict([('id', 9),\n",
    "                         ('latitude', home_lat + -1 * dlat),\n",
    "                         ('longitude', home_long + 1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 10\n",
    "            OrderedDict([('id', 10),\n",
    "                         ('latitude', home_lat + -2 * dlat),\n",
    "                         ('longitude', home_long + 1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 11\n",
    "            OrderedDict([('id', 11),\n",
    "                         ('latitude', home_lat + 2 * dlat),\n",
    "                         ('longitude', home_long + 0 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 12\n",
    "            OrderedDict([('id', 12),\n",
    "                         ('latitude', home_lat + 1 * dlat),\n",
    "                         ('longitude', home_long + 0 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 13\n",
    "            OrderedDict([('id', 13),\n",
    "                         ('latitude', home_lat + 0 * dlat),\n",
    "                         ('longitude', home_long + 0 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 14\n",
    "            OrderedDict([('id', 14),\n",
    "                         ('latitude', home_lat + -1 * dlat),\n",
    "                         ('longitude', home_long + 0 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 15\n",
    "            OrderedDict([('id', 15),\n",
    "                         ('latitude', home_lat + -2 * dlat),\n",
    "                         ('longitude', home_long + 0 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 16\n",
    "            OrderedDict([('id', 16),\n",
    "                         ('latitude', home_lat + 2 * dlat),\n",
    "                         ('longitude', home_long + -1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 17\n",
    "            OrderedDict([('id', 17),\n",
    "                         ('latitude', home_lat + 1 * dlat),\n",
    "                         ('longitude', home_long + -1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 18\n",
    "            OrderedDict([('id', 18),\n",
    "                         ('latitude', home_lat + 0 * dlat),\n",
    "                         ('longitude', home_long + -1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 19\n",
    "            OrderedDict([('id', 19),\n",
    "                         ('latitude', home_lat + -1 * dlat),\n",
    "                         ('longitude', home_long + -1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 20\n",
    "            OrderedDict([('id', 20),\n",
    "                         ('latitude', home_lat + -2 * dlat),\n",
    "                         ('longitude', home_long + -1 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 21\n",
    "            OrderedDict([('id', 21),\n",
    "                         ('latitude', home_lat + 2 * dlat),\n",
    "                         ('longitude', home_long + -2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 22\n",
    "            OrderedDict([('id', 22),\n",
    "                         ('latitude', home_lat + 1 * dlat),\n",
    "                         ('longitude', home_long + -2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 23\n",
    "            OrderedDict([('id', 23),\n",
    "                         ('latitude', home_lat + 0 * dlat),\n",
    "                         ('longitude', home_long + -2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 24\n",
    "            OrderedDict([('id', 24),\n",
    "                         ('latitude', home_lat + -1 * dlat),\n",
    "                         ('longitude', home_long + -2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            # cell no. 25\n",
    "            OrderedDict([('id', 25),\n",
    "                         ('latitude', home_lat + -2 * dlat),\n",
    "                         ('longitude', home_long + -2 * dlong),\n",
    "                         ('altitude', altitude)]),\n",
    "            ]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218a6a5",
   "metadata": {},
   "source": [
    "## Drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "154b880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drone:\n",
    "    def __init__(self, drone_ip, num_targets, max_timestep, is_training=False):\n",
    "        self.drone = olympe.Drone(drone_ip)\n",
    "        self.drone.connect()\n",
    "        \n",
    "        self.drone(GPSFixStateChanged(_policy = 'wait'))\n",
    "        self._takeoff()\n",
    "        if not is_training: self._setup_camera()\n",
    "\n",
    "        self.action = Action(self.drone)\n",
    "        \n",
    "        self.is_training = is_training\n",
    "        self.num_targets = num_targets\n",
    "        self.max_timestep = max_timestep\n",
    "        self.timestep = 0\n",
    "        self.visited_targets = np.zeros(self.num_targets, dtype=bool)\n",
    "        self.target_positions = np.zeros(self.num_targets, dtype=np.uint8)\n",
    "    \n",
    "    def take_action(self, action):\n",
    "        old_cell, new_cell, action_name = self.action.take_action(action)\n",
    "        self.timestep += 1\n",
    "        \n",
    "        Simulation.cease_targets()\n",
    "        time.sleep(0.1)\n",
    "        detected_targets = self._detect_targets(new_cell)\n",
    "        \n",
    "        reward = self._get_reward(detected_targets) # !!! _get_reward must come before self.visited_targets is changed in _get_state\n",
    "        state = self._get_state(new_cell, detected_targets) \n",
    "        if self.timestep >= self.max_timestep or np.all(self.visited_targets):\n",
    "            done = True\n",
    "            self.visited_targets[:] = False\n",
    "        else:\n",
    "            done = False\n",
    "        info = {\n",
    "            \"action\": str(action_name), \n",
    "            \"direction\": \"Cell \" + str(old_cell) + \" --> \" + \"Cell \" + str(new_cell),\n",
    "            \"positions\": self.target_positions\n",
    "        }\n",
    "        \n",
    "        return state, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        old_cell, new_cell = self.action.reset()\n",
    "        detected_targets = self._detect_targets(new_cell)\n",
    "        self.timestep = 0\n",
    "        return self._get_state(new_cell, detected_targets)\n",
    "    \n",
    "    def _get_state(self, new_cell, detected_targets):\n",
    "        # {t, cell_id, [I1, I2, I3, ..., In]}\n",
    "        \n",
    "        self.visited_targets[detected_targets] = True\n",
    "        \n",
    "        return np.concatenate(([self.timestep, new_cell], self.visited_targets)).astype(np.uint8)\n",
    "    \n",
    "    def _get_reward(self, detected_targets):\n",
    "        reward_scale = 1.5\n",
    "        num_new_targets = np.count_nonzero(\n",
    "            detected_targets & (detected_targets != self.visited_targets)\n",
    "        )\n",
    "        return reward_scale * num_new_targets if num_new_targets > 0 else -1\n",
    "        \n",
    "    def _detect_targets(self, cell_id):\n",
    "        self.update_moving_target_positions()\n",
    "        return self.target_positions == cell_id\n",
    "        \n",
    "        if self.is_training:\n",
    "            positions = np.genfromtxt('target_positions.csv', delimiter=',', skip_header=1, dtype=np.uint8)\n",
    "            return positions[:,1] == cell_id\n",
    "        \n",
    "        detected_targets = np.zeros(self.num_targets, dtype=bool)\n",
    "\n",
    "        img = self._take_photo()\n",
    "        if img is None:\n",
    "            return detected_targets\n",
    "        \n",
    "        for result in pyzbar.decode(img):\n",
    "            idx = int(result.data) - 1\n",
    "            try:\n",
    "                detected_targets[idx] = True\n",
    "            except (ValueError, IndexError):\n",
    "                pass\n",
    "                \n",
    "        return detected_targets\n",
    "\n",
    "    def update_moving_target_positions(self):\n",
    "        Simulation.update_moving_target_positions(self.target_positions)\n",
    "        \n",
    "    def _setup_camera(self):\n",
    "        assert self.drone.media_autoconnect\n",
    "        self.drone.media.integrity_check = True\n",
    "        is_indexed = False\n",
    "        while not is_indexed:\n",
    "            is_indexed = self.drone.media(\n",
    "                indexing_state(state=\"indexed\")\n",
    "            ).wait(_timeout=5).success()\n",
    "        \n",
    "        self.drone(set_camera_mode(cam_id=0, value=\"photo\")).wait()\n",
    "\n",
    "        assert self.drone(\n",
    "            set_photo_mode(\n",
    "                cam_id=0,\n",
    "                mode=\"single\",\n",
    "                format= \"rectilinear\",\n",
    "                file_format=\"jpeg\",\n",
    "                # the following are ignored in photo single mode\n",
    "                burst=\"burst_14_over_1s\",\n",
    "                bracketing=\"preset_1ev\",\n",
    "                capture_interval=5.0,\n",
    "            )\n",
    "        ).wait().success()\n",
    "\n",
    "        assert self.drone(\n",
    "            set_target(\n",
    "                gimbal_id=0,\n",
    "                control_mode=\"position\",\n",
    "                yaw_frame_of_reference=\"none\",\n",
    "                yaw=0.0,\n",
    "                pitch_frame_of_reference=\"absolute\",\n",
    "                pitch=-90.0,\n",
    "                roll_frame_of_reference=\"none\",\n",
    "                roll=0.0,\n",
    "                )\n",
    "            >> attitude(\n",
    "                pitch_absolute=-90.0, _policy=\"wait\", _float_tol=(1e-3, 1e-1)\n",
    "                )\n",
    "            ).wait(_timeout=20).success()\n",
    "    \n",
    "    def _take_photo(self):\n",
    "        photo_saved = self.drone(photo_progress(result=\"photo_saved\", _policy=\"wait\"))\n",
    "        self.drone(take_photo(cam_id=0)).wait()\n",
    "        \n",
    "        photo_taken = False\n",
    "        tries = 0\n",
    "        while not photo_taken:\n",
    "            tries += 1\n",
    "            if tries > 3:\n",
    "#                 assert False, \"take_photo timedout\"\n",
    "                print(\"take_photo timedout\")\n",
    "                return None\n",
    "            photo_taken = photo_saved.wait(_timeout=5).success()\n",
    "            \n",
    "        # get the bytes of the image\n",
    "        media_id = photo_saved.received_events().last().args[\"media_id\"]\n",
    "        for _ in range(5):\n",
    "            media_info_response = requests.get(ANAFI_MEDIA_API_URL + media_id, timeout=10)\n",
    "            if media_info_response.status_code == 200:\n",
    "                break\n",
    "        try:\n",
    "            media_info_response.raise_for_status()\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(err)\n",
    "            return None\n",
    "        \n",
    "        resource = media_info_response.json()[\"resources\"][0]\n",
    "        image_response = requests.get(ANAFI_URL + resource[\"url\"], stream=True)\n",
    "        image_response.raise_for_status()\n",
    "        \n",
    "        img = Image.open(BytesIO(image_response.content))\n",
    "        \n",
    "        # delete the image stored on the drone\n",
    "        photo_deleted = False\n",
    "        delete_tries = 0\n",
    "        while not photo_deleted:\n",
    "            delete_tries += 1\n",
    "            if delete_tries > 3:\n",
    "#                 assert False, \"Failed to delete media {} {}\".format(media_id, delete.explain())\n",
    "                print(\"Failed to delete media {} {}\".format(media_id, delete.explain()))\n",
    "                break\n",
    "            delete = delete_media(media_id, _timeout=10)\n",
    "            photo_deleted = self.drone.media(delete).wait().success()\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def _takeoff(self):\n",
    "        takeoff_success = self._success_if_takeoff()\n",
    "        if not takeoff_success:\n",
    "            print(\"Retrying taking off...\")\n",
    "            takeoff_success = self._success_if_takeoff()\n",
    "    \n",
    "    def _success_if_takeoff(self):\n",
    "        return self.drone(\n",
    "                FlyingStateChanged(state=\"hovering\")\n",
    "                | (TakeOff() & FlyingStateChanged(state=\"hovering\"))\n",
    "            ).wait(10).success()\n",
    "        \n",
    "    def _land(self):\n",
    "        self.drone(PCMD(1, 0, 0, 0, 0, 0) >> FlyingStateChanged(state=\"hovering\", _timeout=5)).wait()\n",
    "        assert self.drone(Landing() >> FlyingStateChanged(state=\"landed\")).wait().success()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self._land()\n",
    "        self.drone.disconnect()\n",
    "        del state\n",
    "        del reward\n",
    "        del action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67d9ba",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b6bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    sphinx = jsonrpclib.Server('http://127.0.0.1:8383')\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def disable_battery():\n",
    "        Simulation.sphinx.SetParam(machine='anafi4k',\n",
    "                                   object='lipobattery/lipobattery',\n",
    "                                   parameter='discharge_speed_factor',\n",
    "                                   value='0')\n",
    "    \n",
    "    @staticmethod\n",
    "    def reset_world():\n",
    "        Simulation.sphinx.TriggerAction(machine='world',\n",
    "                                        object='fwman/fwman',\n",
    "                                        action='world_reset_all')\n",
    "    \n",
    "    def find_distance(x, y):\n",
    "        x = x - y[:,np.newaxis]\n",
    "        x = x**2\n",
    "        x = x.sum(axis=2)\n",
    "        x = np.sqrt(x)\n",
    "        return x\n",
    "\n",
    "    # check if the target overlaps with another target or border\n",
    "    @classmethod\n",
    "    def is_overlapping(cls, x, y=None, limit=0.8):\n",
    "        # check with the borders\n",
    "        borders_parallel_y = np.array([12.5, 7.5, 2.5, -2.5, -7.5, -12.5])\n",
    "        x1 = abs(x[:,0] - borders_parallel_y[:,np.newaxis]) < 0.4\n",
    "\n",
    "        borders_parallel_x = np.array([20, 12, 4, -4, -12, -20])\n",
    "        x2 = abs(x[:,1] - borders_parallel_x[:,np.newaxis]) < 0.4\n",
    "        \n",
    "        # check if outside the boundaries\n",
    "        x3 = (\n",
    "            (x[:, 0] > borders_parallel_y.max()) | (x[:, 0] < borders_parallel_y.min()) | \n",
    "            (x[:, 1] > borders_parallel_x.max()) | (x[:, 1] < borders_parallel_x.min())\n",
    "        )\n",
    "\n",
    "        # check with another target\n",
    "        if y is None: y = x\n",
    "        x = cls.find_distance(x, y) < limit\n",
    "        x = np.triu(x, k=1)\n",
    "\n",
    "        x = np.vstack((x, x1, x2, x3))\n",
    "        x = np.any(x, axis=0)\n",
    "        return x\n",
    "    \n",
    "    def coord_to_cellid(locs):\n",
    "        cell_boundaries = [\n",
    "           (locs[:,0] > 7.5) & (locs[:,1] > 12),\n",
    "           (locs[:,0] > 7.5) & (locs[:,1] > 4),\n",
    "           (locs[:,0] > 7.5) & (locs[:,1] > -4),\n",
    "           (locs[:,0] > 7.5) & (locs[:,1] > -12),\n",
    "           (locs[:,0] > 7.5) & (locs[:,1] > -20),\n",
    "           (locs[:,0] > 2.5) & (locs[:,1] > 12),\n",
    "           (locs[:,0] > 2.5) & (locs[:,1] > 4),\n",
    "           (locs[:,0] > 2.5) & (locs[:,1] > -4),\n",
    "           (locs[:,0] > 2.5) & (locs[:,1] > -12),\n",
    "           (locs[:,0] > 2.5) & (locs[:,1] > -20),\n",
    "           (locs[:,0] > -2.5) & (locs[:,1] > 12),\n",
    "           (locs[:,0] > -2.5) & (locs[:,1] > 4),\n",
    "           (locs[:,0] > -2.5) & (locs[:,1] > -4),\n",
    "           (locs[:,0] > -2.5) & (locs[:,1] > -12),\n",
    "           (locs[:,0] > -2.5) & (locs[:,1] > -20),\n",
    "           (locs[:,0] > -7.5) & (locs[:,1] > 12),\n",
    "           (locs[:,0] > -7.5) & (locs[:,1] > 4),\n",
    "           (locs[:,0] > -7.5) & (locs[:,1] > -4),\n",
    "           (locs[:,0] > -7.5) & (locs[:,1] > -12),\n",
    "           (locs[:,0] > -7.5) & (locs[:,1] > -20),\n",
    "           (locs[:,0] > -12.5) & (locs[:,1] > 12),\n",
    "           (locs[:,0] > -12.5) & (locs[:,1] > 4),\n",
    "           (locs[:,0] > -12.5) & (locs[:,1] > -4),\n",
    "           (locs[:,0] > -12.5) & (locs[:,1] > -12),\n",
    "           (locs[:,0] > -12.5) & (locs[:,1] > -20),\n",
    "        ]\n",
    "        cell_ids = np.arange(25) + 1\n",
    "        return np.select(cell_boundaries, cell_ids)\n",
    "    \n",
    "    @classmethod\n",
    "    def gen_targets_pos(cls, num_targets):\n",
    "\n",
    "        num_mobile = 3\n",
    "        num_fixed = num_targets-num_mobile\n",
    "\n",
    "        mu_x_fixed = 7.5\n",
    "        variance_x_fixed = 3\n",
    "        mu_y_fixed = -11 \n",
    "        variance_y_fixed = 5\n",
    "        distribution_fixed = multivariate_normal(\n",
    "            [mu_x_fixed, mu_y_fixed], \n",
    "            [[variance_x_fixed, 0], [0, variance_y_fixed]]\n",
    "        )\n",
    "\n",
    "        mu_x_mobile = -7.5\n",
    "        variance_x_mobile = 3\n",
    "        mu_y_mobile = 5\n",
    "        variance_y_mobile = 30\n",
    "        distribution_mobile = multivariate_normal(\n",
    "            [mu_x_mobile, mu_y_mobile],\n",
    "            [[variance_x_mobile, 0], [0, variance_y_mobile]]\n",
    "        )\n",
    "\n",
    "        locs = np.empty((num_targets,2))\n",
    "        locs[:num_fixed] = distribution_fixed.rvs(size=num_fixed)\n",
    "        locs[num_fixed:] = distribution_mobile.rvs(size=num_mobile)\n",
    "\n",
    "        overlapping_targets = Simulation.is_overlapping(locs)\n",
    "        while np.any(overlapping_targets):\n",
    "            num_fixed_overlaps = np.count_nonzero(overlapping_targets[:num_fixed])\n",
    "            num_mobile_overlaps = np.count_nonzero(overlapping_targets[num_fixed:])\n",
    "            locs[:num_fixed][overlapping_targets[:num_fixed]] = distribution_fixed.rvs(size=num_fixed_overlaps)\n",
    "            locs[num_fixed:][overlapping_targets[num_fixed:]] = distribution_mobile.rvs(size=num_mobile_overlaps)\n",
    "            overlapping_targets = Simulation.is_overlapping(locs)\n",
    "        \n",
    "        np.savetxt('../comm/positions.csv', \n",
    "                   np.hstack((np.arange(len(locs))[:,np.newaxis] + 1, locs)),\n",
    "                   fmt='%.4f',\n",
    "                   delimiter=',',\n",
    "                  )\n",
    "        \n",
    "        return cls.coord_to_cellid(locs) # , locs\n",
    "    \n",
    "    @classmethod\n",
    "    def update_moving_target_positions(cls, arr, ids=[8, 9, 10]):\n",
    "        ids = np.array(ids)\n",
    "        for i in ids:\n",
    "            locs = np.loadtxt(\"../comm/position_\" + str(i) + \".csv\", delimiter=',')\n",
    "            arr[i-1] = cls.coord_to_cellid(locs[np.newaxis,:])\n",
    "            \n",
    "        return arr\n",
    "    \n",
    "    @staticmethod\n",
    "    def cease_targets():\n",
    "        f = open(\"../comm/toggle_movement.txt\", \"w\")\n",
    "        f.write(\"0\")\n",
    "        f.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def move_targets():\n",
    "        f = open(\"../comm/toggle_movement.txt\", \"w\")\n",
    "        f.write(\"1\")\n",
    "        f.close()\n",
    "        \n",
    "    @staticmethod\n",
    "    def reset_targets(release=False):\n",
    "        f = open(\"../comm/reset_position.txt\", \"w\")\n",
    "        if not release:\n",
    "            f.write(\"1\\n\")\n",
    "        else:\n",
    "            f.write(\"0\\n\")\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779876bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simulation.cease_targets()\n",
    "time.sleep(0.1)\n",
    "Simulation.update_moving_target_positions(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(5):\n",
    "cells, locs = Simulation.gen_targets_pos(10)\n",
    "Simulation.reset_targets()\n",
    "time.sleep(0.1)\n",
    "Simulation.reset_targets(release=True)\n",
    "#     time.sleep(1)\n",
    "# for _ in range(10):\n",
    "#     print(sorted(Simulation.gen_targets_pos(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee8aba",
   "metadata": {},
   "source": [
    "# Define a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "341caa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnafiEnv(Env):\n",
    "    def __init__(self, num_targets, max_timestep, drone_ip=\"10.202.0.1\", is_training=False):\n",
    "        super(AnafiEnv, self).__init__()\n",
    "        \n",
    "        Simulation.disable_battery()\n",
    "        Simulation.cease_targets()\n",
    "        \n",
    "        self.num_targets = num_targets\n",
    "        self.max_timestep = max_timestep\n",
    "        self.begin(num_targets, max_timestep, is_training, drone_ip)\n",
    "        \n",
    "        self.action_space = spaces.Discrete(len(self.agent.action))\n",
    "        self.observation_space = spaces.Box( # {t, cell_id, [I1, I2, I3, ..., In]}\n",
    "            low=np.array([0, 1] + num_targets*[0]), \n",
    "            high=np.array([max_timestep, 25] + num_targets*[1]), \n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "        \n",
    "        Simulation.move_targets()\n",
    "    \n",
    "    def begin(self, num_targets, max_timestep, is_training, drone_ip=\"10.202.0.1\"):\n",
    "        self.agent = Drone(drone_ip, num_targets, max_timestep, is_training)\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.agent.take_action(action)\n",
    "        time.sleep(1)\n",
    "        Simulation.move_targets()\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.agent.target_positions = Simulation.gen_targets_pos(self.num_targets)\n",
    "        Simulation.reset_targets()\n",
    "        time.sleep(0.1)\n",
    "        Simulation.reset_targets(release=True)\n",
    "        return self.agent.reset()\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        Simulation.cease_targets()\n",
    "        del self.agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d1b39",
   "metadata": {},
   "source": [
    "# Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc1dbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_info(action, observation, reward, done, info):\n",
    "#     clear_output(wait=True)\n",
    "    print(\"Action:\", info[\"action\"] + \",\", info[\"direction\"])\n",
    "    print(\"Current positions:\", info[\"positions\"])\n",
    "    print(\"State:\", observation)\n",
    "    print(\"Reward:\", reward)\n",
    "#     down_scale = 3\n",
    "#     display(img.resize((img.size[0]//down_scale, img.size[1]//down_scale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a85b8dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: BR, Cell 13 --> Cell 19\n",
      "Current positions: [ 4  9  4  4  9  5  5 11 11 18]\n",
      "State: [ 1 19  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n",
      "Action: FL, Cell 19 --> Cell 13\n",
      "Current positions: [ 4  9  4  4  9  5  5 11  6 13]\n",
      "State: [ 2 13  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: 1.5\n",
      "Action: BR, Cell 13 --> Cell 19\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 3 19  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:15:23,371 \u001b[31m[ERROR] \u001b[0m\tulog - pomp - epoll_ctl(fd=144) err=9(Bad file descriptor)\u001b[0m\n",
      "2022-03-14 15:15:23,375 \u001b[31m[ERROR] \u001b[0m\tulog - pomp - epoll_ctl op=2 cb=0x7f19ee6c1240 userdata=0x7f18f91ba610\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: R, Cell 19 --> Cell 20\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 4 20  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: B, Cell 20 --> Cell 25\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 5 25  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: L, Cell 25 --> Cell 24\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 6 24  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: H, Cell 24 --> Cell 24\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 7 24  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: FL, Cell 24 --> Cell 18\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 8 18  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: B, Cell 18 --> Cell 23\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 9 23  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: FR, Cell 23 --> Cell 19\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [10 19  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: BL, Cell 19 --> Cell 23\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [11 23  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: BR, Cell 23 --> Cell 23\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [12 23  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: FL, Cell 23 --> Cell 17\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [13 17  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: BR, Cell 17 --> Cell 23\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [14 23  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "Action: R, Cell 23 --> Cell 24\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [15 24  0  0  0  0  0  0  0  0  0  1]\n",
      "Reward: -1\n",
      "The episode has ended. Resetting environment...\n",
      "Action: R, Cell 23 --> Cell 24\n",
      "Current positions: [4 9 4 4 9 5 5 6 6 7]\n",
      "State: [ 0 13  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: 0\n",
      "Action: B, Cell 13 --> Cell 18\n",
      "Current positions: [4 9 9 5 4 4 9 6 6 7]\n",
      "State: [ 1 18  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n",
      "Action: L, Cell 18 --> Cell 17\n",
      "Current positions: [4 9 9 5 4 4 9 6 6 7]\n",
      "State: [ 2 17  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n",
      "Action: H, Cell 17 --> Cell 17\n",
      "Current positions: [4 9 9 5 4 4 9 6 6 7]\n",
      "State: [ 3 17  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n",
      "Action: FL, Cell 17 --> Cell 11\n",
      "Current positions: [4 9 9 5 4 4 9 6 6 7]\n",
      "State: [ 4 11  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n",
      "Action: B, Cell 11 --> Cell 16\n",
      "Current positions: [4 9 9 5 4 4 9 6 6 7]\n",
      "State: [ 5 16  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n",
      "Action: FR, Cell 16 --> Cell 12\n",
      "Current positions: [4 9 9 5 4 4 9 6 6 7]\n",
      "State: [ 6 12  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n",
      "Action: BL, Cell 12 --> Cell 16\n",
      "Current positions: [4 9 9 5 4 4 9 6 6 7]\n",
      "State: [ 7 16  0  0  0  0  0  0  0  0  0  0]\n",
      "Reward: -1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     action = env.action_space.sample()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     action \u001b[38;5;241m=\u001b[39m actions[i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(actions)]\n\u001b[0;32m---> 12\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     disp_info(action, observation, reward, done, info)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mAnafiEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m---> 25\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m     Simulation\u001b[38;5;241m.\u001b[39mmove_targets()\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mDrone.take_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     23\u001b[0m Simulation\u001b[38;5;241m.\u001b[39mcease_targets()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m detected_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_targets(new_cell)\n\u001b[1;32m     27\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reward(detected_targets) \u001b[38;5;66;03m# !!! _get_reward must come before self.visited_targets is changed in _get_state\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del env\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "env = AnafiEnv(num_targets=10, max_timestep=15, is_training=True)\n",
    "observation = env.reset()\n",
    "actions = [7, 4, 7, 3, 1, 2, 8, 4, 1, 5, 6]\n",
    "for i in range(1000):\n",
    "#     action = env.action_space.sample()\n",
    "    action = actions[i % len(actions)]\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    disp_info(action, observation, reward, done, info)\n",
    "\n",
    "    if done:\n",
    "        print(\"The episode has ended. Resetting environment...\")\n",
    "        observation = env.reset()\n",
    "        disp_info(action, observation, 0, done, info)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a568a",
   "metadata": {},
   "source": [
    "# Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19743771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq:\n",
    "    :param log_dir: Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: Verbosity level.\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose: int = 1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, 'best_model')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        pass\n",
    "#         # Create folder if needed\n",
    "#         if self.save_path is not None:\n",
    "#             os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\")\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}\")\n",
    "                    self.model.save(self.save_path)\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce3ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del env\n",
    "    del model\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "# Create log dir\n",
    "run = 2\n",
    "log_dir = \"logs/\"\n",
    "monitor_file = os.path.join(log_dir, str(run))\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = AnafiEnv(num_targets=10, max_timestep=15, is_training=True)\n",
    "env = Monitor(env, monitor_file)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=512, log_dir=log_dir)\n",
    "\n",
    "# model = PPO(\"MlpPolicy\", env, n_steps=1024, verbose=1, tensorboard_log=log_dir)\n",
    "model = PPO.load(os.path.join(log_dir, str(run-1) + \"_run\"), env)\n",
    "model.learn(total_timesteps=15_000, callback=callback, tb_log_name=\"PPO_\" + str(run), reset_num_timesteps=False)\n",
    "model.save(os.path.join(log_dir, str(run) + \"_run\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b27d7fa",
   "metadata": {},
   "source": [
    "# Test the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_target_pos():\n",
    "    Simulation.gen_targets_pos(10)\n",
    "    Simulation.reset_targets()\n",
    "    time.sleep(0.1)\n",
    "    Simulation.reset_targets(release=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1be2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del env\n",
    "    del model\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "env = AnafiEnv(num_targets=10, max_timestep=15)\n",
    "model = PPO.load(\"logs/4_run\", env, verbose=1)\n",
    "\n",
    "# header = [\"timestep\", \"action\"]\n",
    "\n",
    "# episode = 9\n",
    "# timestep = 0\n",
    "# file = open('run_' + str(episode+1) + '.csv', 'w', encoding='UTF8', newline='')\n",
    "# writer = csv.writer(file)\n",
    "# writer.writerow(header)\n",
    "\n",
    "obs = env.reset()\n",
    "reset_target_pos()\n",
    "\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "#     timestep += 1\n",
    "    \n",
    "#     writer.writerow([str(timestep), info[\"action\"]])\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        reset_target_pos()\n",
    "        \n",
    "#         if episode >= 10:\n",
    "#             file.close()\n",
    "#             break\n",
    "#         episode += 1\n",
    "#         timestep = 0\n",
    "\n",
    "#         file = open('run_' + str(episode+1) + '.csv', 'w', encoding='UTF8', newline='')\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacef254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
